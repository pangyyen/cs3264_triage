{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_year</th>\n",
       "      <th>admission_month</th>\n",
       "      <th>admission_day</th>\n",
       "      <th>admission_weekday</th>\n",
       "      <th>admission_hour</th>\n",
       "      <th>kindref</th>\n",
       "      <th>ChiefComplaint</th>\n",
       "      <th>...</th>\n",
       "      <th>BlooddpressurSystol</th>\n",
       "      <th>BlooddpressurDiastol</th>\n",
       "      <th>PulseRate</th>\n",
       "      <th>RespiratoryRate</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>O2Saturation</th>\n",
       "      <th>AVPU</th>\n",
       "      <th>TriageGrade</th>\n",
       "      <th>operational_patient</th>\n",
       "      <th>ref_specialist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13960101008</td>\n",
       "      <td>Female</td>\n",
       "      <td>77</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Z03.89</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13960101009</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>T07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13960101010</td>\n",
       "      <td>Female</td>\n",
       "      <td>71</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>R10.84</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13960101011</td>\n",
       "      <td>Male</td>\n",
       "      <td>77</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>R53</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13960101012</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>T79.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143577</th>\n",
       "      <td>14001229114</td>\n",
       "      <td>Female</td>\n",
       "      <td>55</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>K92.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143578</th>\n",
       "      <td>14001229115</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>T18.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143579</th>\n",
       "      <td>14001229117</td>\n",
       "      <td>Female</td>\n",
       "      <td>70</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>R55</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143580</th>\n",
       "      <td>14001229118</td>\n",
       "      <td>Male</td>\n",
       "      <td>67</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>K92.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143581</th>\n",
       "      <td>14001229120</td>\n",
       "      <td>Male</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>N50.819</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143582 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_code  gender  age  admission_year  admission_month  \\\n",
       "0       13960101008  Female   77            2017                3   \n",
       "1       13960101009    Male   42            2017                3   \n",
       "2       13960101010  Female   71            2017                3   \n",
       "3       13960101011    Male   77            2017                3   \n",
       "4       13960101012    Male   39            2017                3   \n",
       "...             ...     ...  ...             ...              ...   \n",
       "143577  14001229114  Female   55            2022                3   \n",
       "143578  14001229115  Female   60            2022                3   \n",
       "143579  14001229117  Female   70            2022                3   \n",
       "143580  14001229118    Male   67            2022                3   \n",
       "143581  14001229120    Male   10            2022                3   \n",
       "\n",
       "        admission_day  admission_weekday  admission_hour  kindref  \\\n",
       "0                  21                  2               2        5   \n",
       "1                  21                  2               2        6   \n",
       "2                  21                  2               2        6   \n",
       "3                  21                  2               2        6   \n",
       "4                  21                  2               2        6   \n",
       "...               ...                ...             ...      ...   \n",
       "143577             20                  0              23        3   \n",
       "143578             20                  0              23        6   \n",
       "143579             20                  0              23        6   \n",
       "143580             20                  0              23        6   \n",
       "143581             20                  0              23        6   \n",
       "\n",
       "       ChiefComplaint  ...  BlooddpressurSystol  BlooddpressurDiastol  \\\n",
       "0              Z03.89  ...                  NaN                   NaN   \n",
       "1                 T07  ...                  NaN                   NaN   \n",
       "2              R10.84  ...                  NaN                   NaN   \n",
       "3                 R53  ...                  NaN                   NaN   \n",
       "4               T79.9  ...                  NaN                   NaN   \n",
       "...               ...  ...                  ...                   ...   \n",
       "143577          K92.2  ...                  NaN                   NaN   \n",
       "143578          T18.9  ...                  NaN                   NaN   \n",
       "143579            R55  ...                  NaN                   NaN   \n",
       "143580          K92.2  ...                  NaN                   NaN   \n",
       "143581        N50.819  ...                  NaN                   NaN   \n",
       "\n",
       "        PulseRate  RespiratoryRate  Temperature  O2Saturation  AVPU  \\\n",
       "0             NaN              NaN          NaN           NaN   NaN   \n",
       "1            86.0             18.0          NaN          96.0     A   \n",
       "2             NaN              NaN          NaN           NaN   NaN   \n",
       "3             NaN              NaN          NaN           NaN   NaN   \n",
       "4             NaN              NaN          NaN           NaN   NaN   \n",
       "...           ...              ...          ...           ...   ...   \n",
       "143577        NaN              NaN          NaN           NaN   NaN   \n",
       "143578        NaN              NaN          NaN           NaN     A   \n",
       "143579        NaN              NaN          NaN           NaN   NaN   \n",
       "143580        NaN              NaN          NaN           NaN   NaN   \n",
       "143581        NaN              NaN          NaN           NaN     A   \n",
       "\n",
       "        TriageGrade  operational_patient  ref_specialist  \n",
       "0                 5                    0               0  \n",
       "1                 3                    0               0  \n",
       "2                 2                    0               0  \n",
       "3                 2                    0               0  \n",
       "4                 4                    1               0  \n",
       "...             ...                  ...             ...  \n",
       "143577            2                    0               0  \n",
       "143578            4                    1               0  \n",
       "143579            1                    0               0  \n",
       "143580            2                    0               0  \n",
       "143581            4                    1               0  \n",
       "\n",
       "[143582 rows x 28 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/ED_triage.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out unnecessary columns\n",
    "df = df.drop(columns=[\"triage_code\", \"admission_year\", \"admission_month\", \"admission_day\", \"admission_weekday\", \"admission_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.071847\n",
       "2    0.564855\n",
       "3    0.239334\n",
       "4    0.123832\n",
       "5    0.000132\n",
       "Name: TriageGrade, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect distribution of TriageGrade\n",
    "df['TriageGrade'].value_counts(normalize=True).sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test one, drop all columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explainer_id: 109327 missing values\n",
      "CriticalStatus: 10380 missing values\n",
      "StuporStatus: 10380 missing values\n",
      "PainGrade: 10316 missing values\n",
      "MentalDistress: 10380 missing values\n",
      "MaterialDistress: 10380 missing values\n",
      "Source: 87549 missing values\n",
      "BlooddpressurSystol: 118921 missing values\n",
      "BlooddpressurDiastol: 118622 missing values\n",
      "PulseRate: 108360 missing values\n",
      "RespiratoryRate: 110143 missing values\n",
      "Temperature: 143443 missing values\n",
      "O2Saturation: 105923 missing values\n",
      "AVPU: 90558 missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.000008\n",
       "2    0.608865\n",
       "3    0.257962\n",
       "4    0.133024\n",
       "5    0.000143\n",
       "Name: TriageGrade, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df.isnull().sum() # default value for the axis parameter in isnull() is 0, which means it operates column-wise.\n",
    "columns_with_missing_values = missing_values[missing_values > 0].index\n",
    "\n",
    "# print the columns with missing values and their counts\n",
    "for column in columns_with_missing_values:\n",
    "    print(f\"{column}: {missing_values[column]} missing values\")\n",
    "\n",
    "# drop columns with missing values > 20%\n",
    "df = df.drop(columns=missing_values[missing_values > 0.2 * len(df)].index)\n",
    "\n",
    "# We remove the rows with missing values in the remaining columns\n",
    "df = df.dropna()\n",
    "\n",
    "# Check the distribution of TriageGrade again\n",
    "df['TriageGrade'].value_counts(normalize=True).sort_index(ascending=True)\n",
    "\n",
    "# It seems the missing values were due to NeedFastExecute being True, which resulted in the loss of most triage grade 1 patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect how NeedFastExecute is distributed across TriageGrade\n",
    "df.groupby('TriageGrade')['NeedFastExecute'].value_counts(normalize=True).unstack().fillna(0).sort_index(ascending=True)\n",
    "\n",
    "# We can drop the NeedFastExecute column, as it is directly related to TriageGrade = 1. We can also drop rows with NeedFastExecute/TriageGrade = 1\n",
    "df = df.drop(columns=['NeedFastExecute'])\n",
    "df = df[df['TriageGrade'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'kindref', 'CriticalStatus', 'StuporStatus', 'PainGrade',\n",
       "       'MentalDistress', 'MaterialDistress', 'TriageGrade',\n",
       "       'operational_patient', 'ref_specialist',\n",
       "       ...\n",
       "       'ChiefComplaint_Z93.1', 'ChiefComplaint_Z93.2', 'ChiefComplaint_Z93.5',\n",
       "       'ChiefComplaint_Z94', 'ChiefComplaint_Z94.0', 'ChiefComplaint_Z94.4',\n",
       "       'ChiefComplaint_Z95.0', 'ChiefComplaint_Z95.5', 'ChiefComplaint_Z96.89',\n",
       "       'ChiefComplaint_Z98.890'],\n",
       "      dtype='object', length=897)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the categorical variables\n",
    "df = pd.get_dummies(df, columns=[\"gender\", \"ChiefComplaint\"], drop_first=True)\n",
    "\n",
    "# Check the new columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['TriageGrade'], axis=1)\n",
    "y = df['TriageGrade']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X_train, X_test, y_train, y_test, model):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "    \n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "    \n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00     64864\n",
      "           3       0.95      0.88      0.91     27479\n",
      "           4       0.80      0.92      0.85     14201\n",
      "           5       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.96    106560\n",
      "   macro avg       0.69      0.70      0.69    106560\n",
      "weighted avg       0.96      0.96      0.96    106560\n",
      "\n",
      "Accuracy of all classes: 0.9568318318318318\n",
      "Macro F1 score: 0.6915887320094003\n",
      "Micro F1 score: 0.9568318318318318\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00     16238\n",
      "           3       0.94      0.86      0.90      6882\n",
      "           4       0.77      0.90      0.83      3518\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95     26641\n",
      "   macro avg       0.68      0.69      0.68     26641\n",
      "weighted avg       0.95      0.95      0.95     26641\n",
      "\n",
      "Accuracy of all classes: 0.9506024548628055\n",
      "Macro F1 score: 0.6830745683923687\n",
      "Micro F1 score: 0.9506024548628055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "# Suppress the warning for zero division\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning, module='sklearn.metrics._classification')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(min_samples_split=20, max_depth=10, min_samples_leaf=2)\n",
    "# model = DecisionTreeClassifier()\n",
    "\n",
    "train_decision_tree(X_train, X_test, y_train, y_test, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def train_logistic_regression(X_train, X_test, y_train, y_test, model, n_components):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    y_pred_train = model.predict(X_train_pca)\n",
    "\n",
    "    # Predict probabilities for AUC calculation\n",
    "    y_pred_proba = model.predict_proba(X_test_pca)\n",
    "    y_pred_train_proba = model.predict_proba(X_train_pca)\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_train)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_test = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.85      0.92      0.88     64864\n",
      "           3       0.63      0.49      0.55     27479\n",
      "           4       0.77      0.80      0.79     14201\n",
      "           5       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80    106560\n",
      "   macro avg       0.56      0.55      0.56    106560\n",
      "weighted avg       0.78      0.80      0.79    106560\n",
      "\n",
      "Accuracy of all classes: 0.7950168918918918\n",
      "Macro F1 score: 0.5561741476647923\n",
      "Micro F1 score: 0.7950168918918918\n",
      "AUC: 0.8945250200034696\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.85      0.92      0.88     16238\n",
      "           3       0.64      0.49      0.56      6882\n",
      "           4       0.78      0.81      0.79      3518\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.80     26641\n",
      "   macro avg       0.57      0.56      0.56     26641\n",
      "weighted avg       0.78      0.80      0.79     26641\n",
      "\n",
      "Accuracy of all classes: 0.7960286776021921\n",
      "Macro F1 score: 0.5576087987610351\n",
      "Micro F1 score: 0.7960286776021921\n",
      "AUC: 0.8825635977179829\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model = LogisticRegression(max_iter=300, random_state=42)\n",
    "train_logistic_regression(X_train, X_test, y_train, y_test, model, n_components=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest(X_train, X_test, y_train, y_test, model):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "    # Predict probabilities for AUC calculation\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "    y_pred_train_proba = model.predict_proba(X_train_scaled)\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_train)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_test = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00     64864\n",
      "           3       0.98      0.95      0.97     27479\n",
      "           4       0.91      0.97      0.94     14201\n",
      "           5       1.00      0.69      0.81        16\n",
      "\n",
      "    accuracy                           0.98    106560\n",
      "   macro avg       0.97      0.90      0.93    106560\n",
      "weighted avg       0.98      0.98      0.98    106560\n",
      "\n",
      "Accuracy of all classes: 0.9841028528528528\n",
      "Macro F1 score: 0.9317081051547461\n",
      "Micro F1 score: 0.9841028528528528\n",
      "AUC: 0.9991222809505041\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00     16238\n",
      "           3       0.91      0.88      0.89      6882\n",
      "           4       0.78      0.85      0.81      3518\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95     26641\n",
      "   macro avg       0.67      0.68      0.68     26641\n",
      "weighted avg       0.95      0.95      0.95     26641\n",
      "\n",
      "Accuracy of all classes: 0.9466611613678165\n",
      "Macro F1 score: 0.6767874584674001\n",
      "Micro F1 score: 0.9466611613678165\n",
      "AUC: 0.8647708013340419\n"
     ]
    }
   ],
   "source": [
    "# model = RandomForestClassifier(random_state=42, max_depth=10, min_samples_leaf=2)\n",
    "model = RandomForestClassifier()\n",
    "train_random_forest(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use neural network to predict esi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "def train_neural_network(X_train, X_test, y_train, y_test, model, n_components):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    y_pred_train = model.predict(X_train_pca)\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00     64864\n",
      "           3       0.95      0.87      0.91     27479\n",
      "           4       0.80      0.93      0.86     14201\n",
      "           5       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.95    106560\n",
      "   macro avg       0.69      0.70      0.69    106560\n",
      "weighted avg       0.96      0.95      0.95    106560\n",
      "\n",
      "Accuracy of all classes: 0.9542323573573573\n",
      "Macro F1 score: 0.690890934100886\n",
      "Micro F1 score: 0.9542323573573573\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.99      0.99      0.99     16238\n",
      "           3       0.93      0.85      0.89      6882\n",
      "           4       0.78      0.91      0.84      3518\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.94     26641\n",
      "   macro avg       0.67      0.69      0.68     26641\n",
      "weighted avg       0.95      0.94      0.94     26641\n",
      "\n",
      "Accuracy of all classes: 0.9441462407567284\n",
      "Macro F1 score: 0.679546594142739\n",
      "Micro F1 score: 0.9441462407567284\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model = MLPClassifier(hidden_layer_sizes=(64, 16), max_iter=100, random_state=42)\n",
    "train_neural_network(X_train, X_test, y_train, y_test, model, n_components=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect relationship between NeedFastExecute and TriageGrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NeedFastExecute</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriageGrade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "NeedFastExecute         0         1         2\n",
       "TriageGrade                                  \n",
       "1                0.000097  0.999903  0.000000\n",
       "2                0.000012  0.000000  0.999988\n",
       "3                0.000087  0.000000  0.999913\n",
       "4                0.003431  0.000000  0.996569\n",
       "5                0.000000  0.000000  1.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinitialise data\n",
    "df = pd.read_csv('./data/ED_triage.csv')\n",
    "\n",
    "# inspect distribution of TriageGrade against NeedFastExecute\n",
    "df.groupby('TriageGrade')['NeedFastExecute'].value_counts(normalize=True).unstack().fillna(0).sort_index(ascending=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
