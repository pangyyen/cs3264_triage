{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep_name</th>\n",
       "      <th>esi</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "      <th>lang</th>\n",
       "      <th>religion</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>employstatus</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginaldischarge</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Retired</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Retired</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Single</td>\n",
       "      <td>Disabled</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 972 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dep_name  esi    age  gender           ethnicity  \\\n",
       "0           B  4.0   40.0    Male  Hispanic or Latino   \n",
       "1           B  4.0   66.0    Male  Hispanic or Latino   \n",
       "2           B  2.0   66.0    Male  Hispanic or Latino   \n",
       "3           A  2.0   66.0    Male  Hispanic or Latino   \n",
       "4           A  3.0   84.0  Female  Hispanic or Latino   \n",
       "...       ...  ...    ...     ...                 ...   \n",
       "4995        B  3.0  100.0  Female        Non-Hispanic   \n",
       "4996        B  4.0   26.0  Female             Unknown   \n",
       "4997        B  3.0   25.0    Male  Hispanic or Latino   \n",
       "4998        C  4.0   26.0    Male  Hispanic or Latino   \n",
       "4999        B  2.0   28.0    Male        Non-Hispanic   \n",
       "\n",
       "                                           race     lang     religion  \\\n",
       "0                            White or Caucasian  English          NaN   \n",
       "1     Native Hawaiian or Other Pacific Islander  English  Pentecostal   \n",
       "2     Native Hawaiian or Other Pacific Islander  English  Pentecostal   \n",
       "3     Native Hawaiian or Other Pacific Islander  English  Pentecostal   \n",
       "4                                         Other    Other  Pentecostal   \n",
       "...                                         ...      ...          ...   \n",
       "4995                         White or Caucasian  English     Catholic   \n",
       "4996                         White or Caucasian  English     Catholic   \n",
       "4997                         White or Caucasian  English          NaN   \n",
       "4998                         White or Caucasian  English          NaN   \n",
       "4999                         White or Caucasian  English     Catholic   \n",
       "\n",
       "     maritalstatus  employstatus  ... cc_vaginaldischarge cc_vaginalpain  \\\n",
       "0           Single     Full Time  ...                 0.0            0.0   \n",
       "1          Married  Not Employed  ...                 0.0            0.0   \n",
       "2          Married  Not Employed  ...                 0.0            0.0   \n",
       "3          Married  Not Employed  ...                 0.0            0.0   \n",
       "4          Widowed       Retired  ...                 0.0            0.0   \n",
       "...            ...           ...  ...                 ...            ...   \n",
       "4995       Widowed       Retired  ...                 0.0            0.0   \n",
       "4996        Single     Full Time  ...                 0.0            0.0   \n",
       "4997        Single     Full Time  ...                 0.0            0.0   \n",
       "4998        Single     Full Time  ...                 0.0            0.0   \n",
       "4999        Single      Disabled  ...                 0.0            0.0   \n",
       "\n",
       "     cc_weakness cc_wheezing cc_withdrawal-alcohol cc_woundcheck  \\\n",
       "0            0.0         0.0                   0.0           0.0   \n",
       "1            0.0         0.0                   0.0           0.0   \n",
       "2            0.0         0.0                   0.0           0.0   \n",
       "3            0.0         0.0                   0.0           0.0   \n",
       "4            0.0         0.0                   0.0           0.0   \n",
       "...          ...         ...                   ...           ...   \n",
       "4995         0.0         0.0                   0.0           0.0   \n",
       "4996         0.0         0.0                   0.0           0.0   \n",
       "4997         0.0         0.0                   0.0           0.0   \n",
       "4998         0.0         0.0                   0.0           0.0   \n",
       "4999         0.0         0.0                   0.0           0.0   \n",
       "\n",
       "     cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  cc_wristpain  \n",
       "0                  0.0                    0.0             0.0           0.0  \n",
       "1                  0.0                    0.0             0.0           0.0  \n",
       "2                  0.0                    0.0             0.0           0.0  \n",
       "3                  0.0                    0.0             0.0           0.0  \n",
       "4                  0.0                    0.0             0.0           0.0  \n",
       "...                ...                    ...             ...           ...  \n",
       "4995               0.0                    0.0             0.0           0.0  \n",
       "4996               0.0                    0.0             0.0           0.0  \n",
       "4997               0.0                    0.0             0.0           0.0  \n",
       "4998               0.0                    0.0             0.0           0.0  \n",
       "4999               0.0                    0.0             0.0           0.0  \n",
       "\n",
       "[5000 rows x 972 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/5v_cleandf_truncated.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "972"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients with each ESI level that were discharged\n",
      "esi\n",
      "3.0    1496\n",
      "4.0     991\n",
      "2.0     570\n",
      "5.0     181\n",
      "1.0      10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "number of patients with each ESI level that were admitted\n",
      "esi\n",
      "2.0    893\n",
      "3.0    773\n",
      "1.0     44\n",
      "4.0     26\n",
      "5.0      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# slice out the esi and disposition columns\n",
    "df_slice_esi = df[[\"esi\", \"disposition\"]]\n",
    "\n",
    "discharge_counts = df_slice_esi[df_slice_esi['disposition'] == 'Discharge']['esi'].value_counts()\n",
    "admit_counts = df_slice_esi[df_slice_esi['disposition'] == 'Admit']['esi'].value_counts()\n",
    "\n",
    "import pprint\n",
    "\n",
    "print(\"number of patients with each ESI level that were discharged\")\n",
    "pprint.pprint(discharge_counts) \n",
    "print()\n",
    "\n",
    "print(\"number of patients with each ESI level that were admitted\")\n",
    "pprint.pprint(admit_counts)\n",
    "\n",
    "# the lower ESI: more severe\n",
    "# the higher ESI: less severe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of patients with each ESI level that were discharged\n",
      "esi\n",
      "3.0    46.06\n",
      "4.0    30.51\n",
      "2.0    17.55\n",
      "5.0     5.57\n",
      "1.0     0.31\n",
      "Name: count, dtype: float64\n",
      "\n",
      "ratio of patients with each ESI level that were admitted\n",
      "esi\n",
      "2.0    51.41\n",
      "3.0    44.50\n",
      "1.0     2.53\n",
      "4.0     1.50\n",
      "5.0     0.06\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"ratio of patients with each ESI level that were discharged\")\n",
    "pprint.pprint(round(discharge_counts/ discharge_counts.sum() * 100, 2))\n",
    "print()\n",
    "\n",
    "print(\"ratio of patients with each ESI level that were admitted\")\n",
    "pprint.pprint(round(admit_counts/ admit_counts.sum() * 100, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESI 1:\n",
      "             count  ratio\n",
      "disposition              \n",
      "Admit           44  81.48\n",
      "Discharge       10  18.52\n",
      "\n",
      "ESI 2:\n",
      "             count  ratio\n",
      "disposition              \n",
      "Admit          893  61.04\n",
      "Discharge      570  38.96\n",
      "\n",
      "ESI 3:\n",
      "             count  ratio\n",
      "disposition              \n",
      "Discharge     1496  65.93\n",
      "Admit          773  34.07\n",
      "\n",
      "ESI 4:\n",
      "             count  ratio\n",
      "disposition              \n",
      "Discharge      991  97.44\n",
      "Admit           26   2.56\n",
      "\n",
      "ESI 5:\n",
      "             count  ratio\n",
      "disposition              \n",
      "Discharge      181  99.45\n",
      "Admit            1   0.55\n"
     ]
    }
   ],
   "source": [
    "# slice out the esi and disposition columns\n",
    "df_slice_esi = df[[\"esi\", \"disposition\"]]\n",
    "\n",
    "# Function to calculate count and ratio\n",
    "def calculate_count_and_ratio(df, esi_level):\n",
    "    df_filtered = df[df['esi'] == esi_level]\n",
    "    count = df_filtered['disposition'].value_counts()\n",
    "    ratio = count / count.sum()\n",
    "    result_df = pd.DataFrame({'count': count, 'ratio': round(ratio * 100,2)})\n",
    "    return result_df\n",
    "\n",
    "# Apply the function to each ESI level\n",
    "esi_1 = calculate_count_and_ratio(df, 1)\n",
    "esi_2 = calculate_count_and_ratio(df, 2)\n",
    "esi_3 = calculate_count_and_ratio(df, 3)\n",
    "esi_4 = calculate_count_and_ratio(df, 4)\n",
    "esi_5 = calculate_count_and_ratio(df, 5)\n",
    "\n",
    "# Print the results\n",
    "print(\"ESI 1:\")\n",
    "pprint.pprint(esi_1)\n",
    "print(\"\\nESI 2:\")\n",
    "pprint.pprint(esi_2)\n",
    "print(\"\\nESI 3:\")\n",
    "pprint.pprint(esi_3)\n",
    "print(\"\\nESI 4:\")\n",
    "pprint.pprint(esi_4)\n",
    "print(\"\\nESI 5:\")\n",
    "pprint.pprint(esi_5)\n",
    "\n",
    "# the lower ESI: more severe\n",
    "# the higher ESI: less severe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(esi_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test one, drop all columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esi</th>\n",
       "      <th>religion</th>\n",
       "      <th>arrivalmode</th>\n",
       "      <th>absolutelymphocytecount_last</th>\n",
       "      <th>acetonebld_last</th>\n",
       "      <th>alanineaminotransferase(alt)_last</th>\n",
       "      <th>albumin_last</th>\n",
       "      <th>alkphos_last</th>\n",
       "      <th>anc(absneutrophilcount)_last</th>\n",
       "      <th>aniongap_last</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginaldischarge</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Car</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>ambulance</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      esi     religion arrivalmode  absolutelymphocytecount_last  \\\n",
       "0     4.0          NaN     Walk-in                           NaN   \n",
       "1     4.0  Pentecostal         Car                           NaN   \n",
       "2     2.0  Pentecostal     Walk-in                           NaN   \n",
       "3     2.0  Pentecostal         Car                           1.9   \n",
       "4     3.0  Pentecostal     Walk-in                           NaN   \n",
       "...   ...          ...         ...                           ...   \n",
       "4995  3.0     Catholic   ambulance                           0.9   \n",
       "4996  4.0     Catholic         Car                           NaN   \n",
       "4997  3.0          NaN         Car                           NaN   \n",
       "4998  4.0          NaN         Car                           NaN   \n",
       "4999  2.0     Catholic     Walk-in                           NaN   \n",
       "\n",
       "      acetonebld_last  alanineaminotransferase(alt)_last  albumin_last  \\\n",
       "0                 NaN                                NaN           NaN   \n",
       "1                 NaN                                NaN           NaN   \n",
       "2                 NaN                                NaN           NaN   \n",
       "3                 NaN                               12.0           NaN   \n",
       "4                 NaN                                NaN           NaN   \n",
       "...               ...                                ...           ...   \n",
       "4995              NaN                                NaN           NaN   \n",
       "4996              NaN                                NaN           NaN   \n",
       "4997              NaN                                NaN           NaN   \n",
       "4998              NaN                                NaN           NaN   \n",
       "4999              NaN                                NaN           NaN   \n",
       "\n",
       "      alkphos_last  anc(absneutrophilcount)_last  aniongap_last  ...  \\\n",
       "0              NaN                           NaN            NaN  ...   \n",
       "1              NaN                           NaN            NaN  ...   \n",
       "2              NaN                           NaN            NaN  ...   \n",
       "3             71.0                           9.2            NaN  ...   \n",
       "4              NaN                           NaN            NaN  ...   \n",
       "...            ...                           ...            ...  ...   \n",
       "4995           NaN                           5.5           14.0  ...   \n",
       "4996           NaN                           NaN            NaN  ...   \n",
       "4997           NaN                           NaN            NaN  ...   \n",
       "4998           NaN                           NaN            NaN  ...   \n",
       "4999           NaN                           NaN            NaN  ...   \n",
       "\n",
       "      cc_vaginaldischarge  cc_vaginalpain  cc_weakness  cc_wheezing  \\\n",
       "0                     0.0             0.0          0.0          0.0   \n",
       "1                     0.0             0.0          0.0          0.0   \n",
       "2                     0.0             0.0          0.0          0.0   \n",
       "3                     0.0             0.0          0.0          0.0   \n",
       "4                     0.0             0.0          0.0          0.0   \n",
       "...                   ...             ...          ...          ...   \n",
       "4995                  0.0             0.0          0.0          0.0   \n",
       "4996                  0.0             0.0          0.0          0.0   \n",
       "4997                  0.0             0.0          0.0          0.0   \n",
       "4998                  0.0             0.0          0.0          0.0   \n",
       "4999                  0.0             0.0          0.0          0.0   \n",
       "\n",
       "      cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0                       0.0            0.0                0.0   \n",
       "1                       0.0            0.0                0.0   \n",
       "2                       0.0            0.0                0.0   \n",
       "3                       0.0            0.0                0.0   \n",
       "4                       0.0            0.0                0.0   \n",
       "...                     ...            ...                ...   \n",
       "4995                    0.0            0.0                0.0   \n",
       "4996                    0.0            0.0                0.0   \n",
       "4997                    0.0            0.0                0.0   \n",
       "4998                    0.0            0.0                0.0   \n",
       "4999                    0.0            0.0                0.0   \n",
       "\n",
       "      cc_woundre-evaluation  cc_wristinjury  cc_wristpain  \n",
       "0                       0.0             0.0           0.0  \n",
       "1                       0.0             0.0           0.0  \n",
       "2                       0.0             0.0           0.0  \n",
       "3                       0.0             0.0           0.0  \n",
       "4                       0.0             0.0           0.0  \n",
       "...                     ...             ...           ...  \n",
       "4995                    0.0             0.0           0.0  \n",
       "4996                    0.0             0.0           0.0  \n",
       "4997                    0.0             0.0           0.0  \n",
       "4998                    0.0             0.0           0.0  \n",
       "4999                    0.0             0.0           0.0  \n",
       "\n",
       "[5000 rows x 590 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df.isnull().sum() # default value for the axis parameter in isnull() is 0, which means it operates column-wise.\n",
    "columns_with_missing_values = missing_values[missing_values > 0].index\n",
    "print(len(columns_with_missing_values))\n",
    "\n",
    "# drop all columns with null values\n",
    "df_missing = df[df.isnull().any(axis=1)][columns_with_missing_values]\n",
    "df_missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns with missing values > 20%\n",
    "columns_to_drop= missing_values[missing_values > 0.2 * len(df)].index.tolist()\n",
    "len(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = columns_to_drop + [\"religion\"]\n",
    "len(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep_name</th>\n",
       "      <th>esi</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "      <th>lang</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>employstatus</th>\n",
       "      <th>insurance_status</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginaldischarge</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Single</td>\n",
       "      <td>Disabled</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dep_name  esi    age  gender           ethnicity  \\\n",
       "0           B  4.0   40.0    Male  Hispanic or Latino   \n",
       "1           B  4.0   66.0    Male  Hispanic or Latino   \n",
       "2           B  2.0   66.0    Male  Hispanic or Latino   \n",
       "3           A  2.0   66.0    Male  Hispanic or Latino   \n",
       "4           A  3.0   84.0  Female  Hispanic or Latino   \n",
       "...       ...  ...    ...     ...                 ...   \n",
       "4995        B  3.0  100.0  Female        Non-Hispanic   \n",
       "4996        B  4.0   26.0  Female             Unknown   \n",
       "4997        B  3.0   25.0    Male  Hispanic or Latino   \n",
       "4998        C  4.0   26.0    Male  Hispanic or Latino   \n",
       "4999        B  2.0   28.0    Male        Non-Hispanic   \n",
       "\n",
       "                                           race     lang maritalstatus  \\\n",
       "0                            White or Caucasian  English        Single   \n",
       "1     Native Hawaiian or Other Pacific Islander  English       Married   \n",
       "2     Native Hawaiian or Other Pacific Islander  English       Married   \n",
       "3     Native Hawaiian or Other Pacific Islander  English       Married   \n",
       "4                                         Other    Other       Widowed   \n",
       "...                                         ...      ...           ...   \n",
       "4995                         White or Caucasian  English       Widowed   \n",
       "4996                         White or Caucasian  English        Single   \n",
       "4997                         White or Caucasian  English        Single   \n",
       "4998                         White or Caucasian  English        Single   \n",
       "4999                         White or Caucasian  English        Single   \n",
       "\n",
       "      employstatus insurance_status  ... cc_vaginaldischarge cc_vaginalpain  \\\n",
       "0        Full Time            Other  ...                 0.0            0.0   \n",
       "1     Not Employed       Commercial  ...                 0.0            0.0   \n",
       "2     Not Employed       Commercial  ...                 0.0            0.0   \n",
       "3     Not Employed       Commercial  ...                 0.0            0.0   \n",
       "4          Retired         Medicare  ...                 0.0            0.0   \n",
       "...            ...              ...  ...                 ...            ...   \n",
       "4995       Retired         Medicare  ...                 0.0            0.0   \n",
       "4996     Full Time       Commercial  ...                 0.0            0.0   \n",
       "4997     Full Time       Commercial  ...                 0.0            0.0   \n",
       "4998     Full Time       Commercial  ...                 0.0            0.0   \n",
       "4999      Disabled         Medicaid  ...                 0.0            0.0   \n",
       "\n",
       "     cc_weakness cc_wheezing cc_withdrawal-alcohol cc_woundcheck  \\\n",
       "0            0.0         0.0                   0.0           0.0   \n",
       "1            0.0         0.0                   0.0           0.0   \n",
       "2            0.0         0.0                   0.0           0.0   \n",
       "3            0.0         0.0                   0.0           0.0   \n",
       "4            0.0         0.0                   0.0           0.0   \n",
       "...          ...         ...                   ...           ...   \n",
       "4995         0.0         0.0                   0.0           0.0   \n",
       "4996         0.0         0.0                   0.0           0.0   \n",
       "4997         0.0         0.0                   0.0           0.0   \n",
       "4998         0.0         0.0                   0.0           0.0   \n",
       "4999         0.0         0.0                   0.0           0.0   \n",
       "\n",
       "      cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  cc_wristpain  \n",
       "0                   0.0                    0.0             0.0           0.0  \n",
       "1                   0.0                    0.0             0.0           0.0  \n",
       "2                   0.0                    0.0             0.0           0.0  \n",
       "3                   0.0                    0.0             0.0           0.0  \n",
       "4                   0.0                    0.0             0.0           0.0  \n",
       "...                 ...                    ...             ...           ...  \n",
       "4995                0.0                    0.0             0.0           0.0  \n",
       "4996                0.0                    0.0             0.0           0.0  \n",
       "4997                0.0                    0.0             0.0           0.0  \n",
       "4998                0.0                    0.0             0.0           0.0  \n",
       "4999                0.0                    0.0             0.0           0.0  \n",
       "\n",
       "[5000 rows x 584 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop `columns_to_drop`\n",
    "df_small = df.drop(columns=columns_to_drop)\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esi</th>\n",
       "      <th>age</th>\n",
       "      <th>2ndarymalig</th>\n",
       "      <th>abdomhernia</th>\n",
       "      <th>abdomnlpain</th>\n",
       "      <th>abortcompl</th>\n",
       "      <th>acqfootdef</th>\n",
       "      <th>acrenlfail</th>\n",
       "      <th>acutecvd</th>\n",
       "      <th>acutemi</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginaldischarge</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 570 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      esi    age  2ndarymalig  abdomhernia  abdomnlpain  abortcompl  \\\n",
       "0     4.0   40.0          0.0          0.0          0.0         0.0   \n",
       "1     4.0   66.0          0.0          0.0          0.0         0.0   \n",
       "2     2.0   66.0          0.0          0.0          0.0         0.0   \n",
       "3     2.0   66.0          0.0          0.0          0.0         0.0   \n",
       "4     3.0   84.0          0.0          0.0          0.0         0.0   \n",
       "...   ...    ...          ...          ...          ...         ...   \n",
       "4995  3.0  100.0          0.0          0.0          0.0         0.0   \n",
       "4996  4.0   26.0          0.0          0.0          0.0         0.0   \n",
       "4997  3.0   25.0          0.0          0.0          0.0         0.0   \n",
       "4998  4.0   26.0          0.0          0.0          0.0         0.0   \n",
       "4999  2.0   28.0          0.0          0.0          0.0         0.0   \n",
       "\n",
       "      acqfootdef  acrenlfail  acutecvd  acutemi  ...  cc_vaginaldischarge  \\\n",
       "0            0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "1            0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "2            0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "3            0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "4            0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "...          ...         ...       ...      ...  ...                  ...   \n",
       "4995         0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "4996         0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "4997         0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "4998         0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "4999         0.0         0.0       0.0      0.0  ...                  0.0   \n",
       "\n",
       "      cc_vaginalpain  cc_weakness  cc_wheezing  cc_withdrawal-alcohol  \\\n",
       "0                0.0          0.0          0.0                    0.0   \n",
       "1                0.0          0.0          0.0                    0.0   \n",
       "2                0.0          0.0          0.0                    0.0   \n",
       "3                0.0          0.0          0.0                    0.0   \n",
       "4                0.0          0.0          0.0                    0.0   \n",
       "...              ...          ...          ...                    ...   \n",
       "4995             0.0          0.0          0.0                    0.0   \n",
       "4996             0.0          0.0          0.0                    0.0   \n",
       "4997             0.0          0.0          0.0                    0.0   \n",
       "4998             0.0          0.0          0.0                    0.0   \n",
       "4999             0.0          0.0          0.0                    0.0   \n",
       "\n",
       "      cc_woundcheck  cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  \\\n",
       "0               0.0                0.0                    0.0             0.0   \n",
       "1               0.0                0.0                    0.0             0.0   \n",
       "2               0.0                0.0                    0.0             0.0   \n",
       "3               0.0                0.0                    0.0             0.0   \n",
       "4               0.0                0.0                    0.0             0.0   \n",
       "...             ...                ...                    ...             ...   \n",
       "4995            0.0                0.0                    0.0             0.0   \n",
       "4996            0.0                0.0                    0.0             0.0   \n",
       "4997            0.0                0.0                    0.0             0.0   \n",
       "4998            0.0                0.0                    0.0             0.0   \n",
       "4999            0.0                0.0                    0.0             0.0   \n",
       "\n",
       "      cc_wristpain  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "4995           0.0  \n",
       "4996           0.0  \n",
       "4997           0.0  \n",
       "4998           0.0  \n",
       "4999           0.0  \n",
       "\n",
       "[5000 rows x 570 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric = df_small.select_dtypes(include='number')\n",
    "df_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_numeric.dropna(inplace=True)\n",
    "print(df_numeric.isnull().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_numeric.drop(['esi'], axis=1)\n",
    "y = df_numeric['esi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X_train, X_test, y_train, y_test, model):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "    \n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "    \n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.83      0.11      0.20        44\n",
      "         2.0       0.76      0.47      0.58      1158\n",
      "         3.0       0.60      0.74      0.66      1813\n",
      "         4.0       0.46      0.56      0.50       809\n",
      "         5.0       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.59      3970\n",
      "   macro avg       0.53      0.38      0.39      3970\n",
      "weighted avg       0.60      0.59      0.58      3970\n",
      "\n",
      "Accuracy of all classes: 0.5919395465994962\n",
      "Macro F1 score: 0.3893401962358779\n",
      "Micro F1 score: 0.5919395465994962\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "         2.0       0.65      0.38      0.48       300\n",
      "         3.0       0.54      0.67      0.60       442\n",
      "         4.0       0.44      0.58      0.50       205\n",
      "         5.0       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.53       993\n",
      "   macro avg       0.33      0.33      0.32       993\n",
      "weighted avg       0.53      0.53      0.51       993\n",
      "\n",
      "Accuracy of all classes: 0.5327291037260826\n",
      "Macro F1 score: 0.3150096137276349\n",
      "Micro F1 score: 0.5327291037260826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "# Suppress the warning for zero division\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning, module='sklearn.metrics._classification')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(min_samples_split=20, max_depth=10, min_samples_leaf=2)\n",
    "# model = DecisionTreeClassifier()\n",
    "\n",
    "train_decision_tree(X_train, X_test, y_train, y_test, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data handling 2: fill in missing value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep_name</th>\n",
       "      <th>esi</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "      <th>lang</th>\n",
       "      <th>religion</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>employstatus</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginaldischarge</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Married</td>\n",
       "      <td>Not Employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Retired</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Retired</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>Single</td>\n",
       "      <td>Disabled</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 972 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dep_name  esi    age  gender           ethnicity  \\\n",
       "0           B  4.0   40.0    Male  Hispanic or Latino   \n",
       "1           B  4.0   66.0    Male  Hispanic or Latino   \n",
       "2           B  2.0   66.0    Male  Hispanic or Latino   \n",
       "3           A  2.0   66.0    Male  Hispanic or Latino   \n",
       "4           A  3.0   84.0  Female  Hispanic or Latino   \n",
       "...       ...  ...    ...     ...                 ...   \n",
       "4995        B  3.0  100.0  Female        Non-Hispanic   \n",
       "4996        B  4.0   26.0  Female             Unknown   \n",
       "4997        B  3.0   25.0    Male  Hispanic or Latino   \n",
       "4998        C  4.0   26.0    Male  Hispanic or Latino   \n",
       "4999        B  2.0   28.0    Male        Non-Hispanic   \n",
       "\n",
       "                                           race     lang     religion  \\\n",
       "0                            White or Caucasian  English     Catholic   \n",
       "1     Native Hawaiian or Other Pacific Islander  English  Pentecostal   \n",
       "2     Native Hawaiian or Other Pacific Islander  English  Pentecostal   \n",
       "3     Native Hawaiian or Other Pacific Islander  English  Pentecostal   \n",
       "4                                         Other    Other  Pentecostal   \n",
       "...                                         ...      ...          ...   \n",
       "4995                         White or Caucasian  English     Catholic   \n",
       "4996                         White or Caucasian  English     Catholic   \n",
       "4997                         White or Caucasian  English     Catholic   \n",
       "4998                         White or Caucasian  English     Catholic   \n",
       "4999                         White or Caucasian  English     Catholic   \n",
       "\n",
       "     maritalstatus  employstatus  ... cc_vaginaldischarge cc_vaginalpain  \\\n",
       "0           Single     Full Time  ...                 0.0            0.0   \n",
       "1          Married  Not Employed  ...                 0.0            0.0   \n",
       "2          Married  Not Employed  ...                 0.0            0.0   \n",
       "3          Married  Not Employed  ...                 0.0            0.0   \n",
       "4          Widowed       Retired  ...                 0.0            0.0   \n",
       "...            ...           ...  ...                 ...            ...   \n",
       "4995       Widowed       Retired  ...                 0.0            0.0   \n",
       "4996        Single     Full Time  ...                 0.0            0.0   \n",
       "4997        Single     Full Time  ...                 0.0            0.0   \n",
       "4998        Single     Full Time  ...                 0.0            0.0   \n",
       "4999        Single      Disabled  ...                 0.0            0.0   \n",
       "\n",
       "     cc_weakness cc_wheezing cc_withdrawal-alcohol cc_woundcheck  \\\n",
       "0            0.0         0.0                   0.0           0.0   \n",
       "1            0.0         0.0                   0.0           0.0   \n",
       "2            0.0         0.0                   0.0           0.0   \n",
       "3            0.0         0.0                   0.0           0.0   \n",
       "4            0.0         0.0                   0.0           0.0   \n",
       "...          ...         ...                   ...           ...   \n",
       "4995         0.0         0.0                   0.0           0.0   \n",
       "4996         0.0         0.0                   0.0           0.0   \n",
       "4997         0.0         0.0                   0.0           0.0   \n",
       "4998         0.0         0.0                   0.0           0.0   \n",
       "4999         0.0         0.0                   0.0           0.0   \n",
       "\n",
       "     cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  cc_wristpain  \n",
       "0                  0.0                    0.0             0.0           0.0  \n",
       "1                  0.0                    0.0             0.0           0.0  \n",
       "2                  0.0                    0.0             0.0           0.0  \n",
       "3                  0.0                    0.0             0.0           0.0  \n",
       "4                  0.0                    0.0             0.0           0.0  \n",
       "...                ...                    ...             ...           ...  \n",
       "4995               0.0                    0.0             0.0           0.0  \n",
       "4996               0.0                    0.0             0.0           0.0  \n",
       "4997               0.0                    0.0             0.0           0.0  \n",
       "4998               0.0                    0.0             0.0           0.0  \n",
       "4999               0.0                    0.0             0.0           0.0  \n",
       "\n",
       "[5000 rows x 972 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled = df.fillna(df.mode().iloc[0])\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "df_filled = df_filled.select_dtypes(include='number')\n",
    "df_filled.dropna(inplace=True)\n",
    "print(df_filled.isnull().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        44\n",
      "         2.0       1.00      1.00      1.00      1158\n",
      "         3.0       1.00      1.00      1.00      1813\n",
      "         4.0       1.00      1.00      1.00       809\n",
      "         5.0       1.00      1.00      1.00       146\n",
      "\n",
      "    accuracy                           1.00      3970\n",
      "   macro avg       1.00      1.00      1.00      3970\n",
      "weighted avg       1.00      1.00      1.00      3970\n",
      "\n",
      "Accuracy of all classes: 0.998992443324937\n",
      "Macro F1 score: 0.9992215209136383\n",
      "Micro F1 score: 0.998992443324937\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.11      0.10      0.11        10\n",
      "         2.0       0.57      0.52      0.54       300\n",
      "         3.0       0.57      0.59      0.58       442\n",
      "         4.0       0.46      0.49      0.48       205\n",
      "         5.0       0.15      0.17      0.16        36\n",
      "\n",
      "    accuracy                           0.52       993\n",
      "   macro avg       0.37      0.37      0.37       993\n",
      "weighted avg       0.53      0.52      0.53       993\n",
      "\n",
      "Accuracy of all classes: 0.5246727089627392\n",
      "Macro F1 score: 0.37163443464069906\n",
      "Micro F1 score: 0.5246727089627392\n"
     ]
    }
   ],
   "source": [
    "X = df_numeric.drop('esi', axis=1)\n",
    "y = df_numeric['esi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "train_decision_tree(X_train, X_test, y_train, y_test, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def train_logistic_regression(X_train, X_test, y_train, y_test, model, n_components):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    y_pred_train = model.predict(X_train_pca)\n",
    "\n",
    "    # Predict probabilities for AUC calculation\n",
    "    y_pred_proba = model.predict_proba(X_test_pca)\n",
    "    y_pred_train_proba = model.predict_proba(X_train_pca)\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_train)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_test = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        44\n",
      "         2.0       0.60      0.28      0.38      1158\n",
      "         3.0       0.48      0.85      0.62      1813\n",
      "         4.0       0.50      0.13      0.21       809\n",
      "         5.0       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.50      3970\n",
      "   macro avg       0.32      0.25      0.24      3970\n",
      "weighted avg       0.50      0.50      0.44      3970\n",
      "\n",
      "Accuracy of all classes: 0.4987405541561713\n",
      "Macro F1 score: 0.24128635209567156\n",
      "Micro F1 score: 0.4987405541561713\n",
      "AUC: 0.717917376410141\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "         2.0       0.58      0.28      0.38       300\n",
      "         3.0       0.46      0.83      0.60       442\n",
      "         4.0       0.48      0.15      0.22       205\n",
      "         5.0       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.48       993\n",
      "   macro avg       0.31      0.25      0.24       993\n",
      "weighted avg       0.48      0.48      0.42       993\n",
      "\n",
      "Accuracy of all classes: 0.4823766364551863\n",
      "Macro F1 score: 0.23891363181883324\n",
      "Micro F1 score: 0.4823766364551863\n",
      "AUC: 0.7006642914448535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model = LogisticRegression(max_iter=300, random_state=42)\n",
    "train_logistic_regression(X_train, X_test, y_train, y_test, model, n_components=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest(X_train, X_test, y_train, y_test, model):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "\n",
    "    # Predict probabilities for AUC calculation\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "    y_pred_train_proba = model.predict_proba(X_train_scaled)\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_train)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_test = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    print(\"AUC:\", auc_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        44\n",
      "         2.0       1.00      1.00      1.00      1158\n",
      "         3.0       1.00      1.00      1.00      1813\n",
      "         4.0       1.00      1.00      1.00       809\n",
      "         5.0       1.00      1.00      1.00       146\n",
      "\n",
      "    accuracy                           1.00      3970\n",
      "   macro avg       1.00      1.00      1.00      3970\n",
      "weighted avg       1.00      1.00      1.00      3970\n",
      "\n",
      "Accuracy of all classes: 0.998992443324937\n",
      "Macro F1 score: 0.9992229975964593\n",
      "Micro F1 score: 0.998992443324937\n",
      "AUC: 0.9999990709946249\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.10      0.18        10\n",
      "         2.0       0.63      0.55      0.59       300\n",
      "         3.0       0.59      0.70      0.64       442\n",
      "         4.0       0.57      0.51      0.53       205\n",
      "         5.0       0.25      0.14      0.18        36\n",
      "\n",
      "    accuracy                           0.59       993\n",
      "   macro avg       0.61      0.40      0.43       993\n",
      "weighted avg       0.59      0.59      0.58       993\n",
      "\n",
      "Accuracy of all classes: 0.5911379657603223\n",
      "Macro F1 score: 0.42568065900029745\n",
      "Micro F1 score: 0.5911379657603223\n",
      "AUC: 0.7911117852091839\n"
     ]
    }
   ],
   "source": [
    "# model = RandomForestClassifier(random_state=42, max_depth=10, min_samples_leaf=2)\n",
    "model = RandomForestClassifier()\n",
    "train_random_forest(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use neural network to predict esi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "def train_neural_network(X_train, X_test, y_train, y_test, model, n_components):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict the target variable for the test set\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    y_pred_train = model.predict(X_train_pca)\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_train, y_pred_train)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    # Calculate accuracy of all classes\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_train, y_pred_train, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_train, y_pred_train, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "\n",
    "    # Calculate accuracy of each class\n",
    "    class_accuracy = classification_report(y_test, y_pred)\n",
    "    print(\"Accuracy of each class:\\n\", class_accuracy)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of all classes:\", accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "    # Calculate micro F1 score\n",
    "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"Micro F1 score:\", micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.98      0.99        44\n",
      "         2.0       0.99      0.98      0.99      1158\n",
      "         3.0       0.99      0.99      0.99      1813\n",
      "         4.0       0.96      0.98      0.97       809\n",
      "         5.0       0.97      0.95      0.96       146\n",
      "\n",
      "    accuracy                           0.98      3970\n",
      "   macro avg       0.98      0.97      0.98      3970\n",
      "weighted avg       0.98      0.98      0.98      3970\n",
      "\n",
      "Accuracy of all classes: 0.9828715365239294\n",
      "Macro F1 score: 0.9778440737526495\n",
      "Micro F1 score: 0.9828715365239294\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.30      0.40        10\n",
      "         2.0       0.60      0.53      0.56       300\n",
      "         3.0       0.59      0.66      0.62       442\n",
      "         4.0       0.56      0.55      0.56       205\n",
      "         5.0       0.16      0.11      0.13        36\n",
      "\n",
      "    accuracy                           0.58       993\n",
      "   macro avg       0.50      0.43      0.45       993\n",
      "weighted avg       0.57      0.58      0.57       993\n",
      "\n",
      "Accuracy of all classes: 0.5750251762336355\n",
      "Macro F1 score: 0.4542416562088693\n",
      "Micro F1 score: 0.5750251762336355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model = MLPClassifier(hidden_layer_sizes=(64, 16), max_iter=100, random_state=42)\n",
    "train_neural_network(X_train, X_test, y_train, y_test, model, n_components=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "def train_neural_network(model, X_train, X_test, y_train, y_test, epochs=100, lr=0.001):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values - 1, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test.values - 1, dtype=torch.long)\n",
    "\n",
    "    # Define the model, loss function, and optimizer\n",
    "    criterion = nn.CrossEntropyLoss() # input is raw logits, target label is class label [0, C)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train = model(X_train_tensor).argmax(dim=1).numpy()\n",
    "        y_pred = model(X_test_tensor).argmax(dim=1).numpy()\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "    print(\"Accuracy of each class:\\n\", classification_report(y_train_tensor, y_pred_train))\n",
    "    print(\"Accuracy of all classes:\", round(accuracy_score(y_train_tensor, y_pred_train), 2))\n",
    "    print(\"Macro F1 score:\", round(f1_score(y_train_tensor, y_pred_train, average='macro'), 2))\n",
    "    print(\"Micro F1 score:\", round(f1_score(y_train_tensor, y_pred_train, average='micro'), 2))\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "    print(\"Accuracy of each class:\\n\", classification_report(y_test_tensor, y_pred))\n",
    "    print(\"Accuracy of all classes:\", round(accuracy_score(y_test_tensor, y_pred), 2))\n",
    "    print(\"Macro F1 score:\", round(f1_score(y_test_tensor, y_pred, average='macro'), 2))\n",
    "    print(\"Micro F1 score:\", round(f1_score(y_test_tensor, y_pred, average='micro'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62        44\n",
      "           1       0.86      0.82      0.84      1158\n",
      "           2       0.84      0.88      0.86      1813\n",
      "           3       0.80      0.86      0.83       809\n",
      "           4       0.89      0.50      0.64       146\n",
      "\n",
      "    accuracy                           0.84      3970\n",
      "   macro avg       0.88      0.70      0.76      3970\n",
      "weighted avg       0.84      0.84      0.84      3970\n",
      "\n",
      "Accuracy of all classes: 0.84\n",
      "Macro F1 score: 0.76\n",
      "Micro F1 score: 0.84\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.40      0.53        10\n",
      "           1       0.64      0.58      0.61       300\n",
      "           2       0.60      0.66      0.63       442\n",
      "           3       0.58      0.61      0.59       205\n",
      "           4       0.29      0.11      0.16        36\n",
      "\n",
      "    accuracy                           0.60       993\n",
      "   macro avg       0.58      0.47      0.51       993\n",
      "weighted avg       0.60      0.60      0.60       993\n",
      "\n",
      "Accuracy of all classes: 0.6\n",
      "Macro F1 score: 0.51\n",
      "Micro F1 score: 0.6\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # self.batch_norm = nn.BatchNorm1d(hidden_dim)  # Add batch normalization layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.batch_norm(out)\n",
    "        return out\n",
    "    \n",
    "# Example usage\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "hidden_dim = 100  # Example hidden layer size\n",
    "model = NeuralNetwork(input_dim=X_train.shape[1], hidden_dim=hidden_dim, output_dim=len(set(y_train)))\n",
    "\n",
    "train_neural_network(model, X_train, X_test, y_train, y_test, epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.27        44\n",
      "           1       0.81      0.78      0.80      1158\n",
      "           2       0.79      0.84      0.82      1813\n",
      "           3       0.78      0.81      0.79       809\n",
      "           4       0.87      0.51      0.64       146\n",
      "\n",
      "    accuracy                           0.80      3970\n",
      "   macro avg       0.85      0.62      0.66      3970\n",
      "weighted avg       0.80      0.80      0.79      3970\n",
      "\n",
      "Accuracy of all classes: 0.8\n",
      "Macro F1 score: 0.66\n",
      "Micro F1 score: 0.8\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.66      0.57      0.61       300\n",
      "           2       0.60      0.67      0.63       442\n",
      "           3       0.55      0.59      0.57       205\n",
      "           4       0.33      0.14      0.20        36\n",
      "\n",
      "    accuracy                           0.60       993\n",
      "   macro avg       0.43      0.39      0.40       993\n",
      "weighted avg       0.59      0.60      0.59       993\n",
      "\n",
      "Accuracy of all classes: 0.6\n",
      "Macro F1 score: 0.4\n",
      "Micro F1 score: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/pangyen/anaconda3/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # self.batch_norm = nn.BatchNorm1d(hidden_dim)  # Add batch normalization layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.batch_norm(out)\n",
    "        return out\n",
    "    \n",
    "# Example usage\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "hidden_dim = 32  # Example hidden layer size\n",
    "model = NeuralNetwork(input_dim=X_train.shape[1], hidden_dim=hidden_dim, output_dim=len(set(y_train)))\n",
    "\n",
    "train_neural_network(model, X_train, X_test, y_train, y_test, epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hanlde imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_neural_network_handle_imbalanced(model, X_train, X_test, y_train, y_test, epochs=100, lr=0.001):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Apply SMOTE to handle data imbalance\n",
    "    smote = SMOTE()\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    print(y_train_resampled.value_counts())\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_resampled.values - 1, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test.values - 1, dtype=torch.long)\n",
    "\n",
    "    # Define the model, loss function, and optimizer\n",
    "    criterion = nn.CrossEntropyLoss() # input is raw logits, target label is class label [0, C)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_train = model(X_train_tensor).argmax(dim=1).numpy()\n",
    "        y_pred = model(X_test_tensor).argmax(dim=1).numpy()\n",
    "\n",
    "    print(\"=====FOR TRAINING:=====\")\n",
    "    print(\"Accuracy of each class:\\n\", classification_report(y_train_tensor, y_pred_train))\n",
    "    print(\"Accuracy of all classes:\", round(accuracy_score(y_train_tensor, y_pred_train), 2))\n",
    "    print(\"Macro F1 score:\", round(f1_score(y_train_tensor, y_pred_train, average='macro'), 2))\n",
    "    print(\"Micro F1 score:\", round(f1_score(y_train_tensor, y_pred_train, average='micro'), 2))\n",
    "\n",
    "    print(\"====FOR TESTING:====\")\n",
    "    print(\"Accuracy of each class:\\n\", classification_report(y_test_tensor, y_pred))\n",
    "    print(\"Accuracy of all classes:\", round(accuracy_score(y_test_tensor, y_pred), 2))\n",
    "    print(\"Macro F1 score:\", round(f1_score(y_test_tensor, y_pred, average='macro'), 2))\n",
    "    print(\"Micro F1 score:\", round(f1_score(y_test_tensor, y_pred, average='micro'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esi\n",
      "3.0    1813\n",
      "4.0    1813\n",
      "2.0    1813\n",
      "5.0    1813\n",
      "1.0    1813\n",
      "Name: count, dtype: int64\n",
      "=====FOR TRAINING:=====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1813\n",
      "           1       0.87      0.86      0.87      1813\n",
      "           2       0.87      0.78      0.82      1813\n",
      "           3       0.86      0.86      0.86      1813\n",
      "           4       0.87      0.95      0.91      1813\n",
      "\n",
      "    accuracy                           0.89      9065\n",
      "   macro avg       0.89      0.89      0.89      9065\n",
      "weighted avg       0.89      0.89      0.89      9065\n",
      "\n",
      "Accuracy of all classes: 0.89\n",
      "Macro F1 score: 0.89\n",
      "Micro F1 score: 0.89\n",
      "====FOR TESTING:====\n",
      "Accuracy of each class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.34        10\n",
      "           1       0.61      0.60      0.60       300\n",
      "           2       0.63      0.57      0.60       442\n",
      "           3       0.56      0.62      0.59       205\n",
      "           4       0.20      0.28      0.23        36\n",
      "\n",
      "    accuracy                           0.58       993\n",
      "   macro avg       0.45      0.51      0.47       993\n",
      "weighted avg       0.59      0.58      0.58       993\n",
      "\n",
      "Accuracy of all classes: 0.58\n",
      "Macro F1 score: 0.47\n",
      "Micro F1 score: 0.58\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Add dropout layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # self.batch_norm = nn.BatchNorm1d(hidden_dim)  # Add batch normalization layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.batch_norm(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "hidden_dim = 128  # Example hidden layer size\n",
    "model = NeuralNetwork(input_dim=X_train.shape[1], hidden_dim=hidden_dim, output_dim=len(set(y_train)))\n",
    "\n",
    "train_neural_network_handle_imbalanced(model, X_train, X_test, y_train, y_test, epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
